{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('../Pyfiles')\n",
    "# Pull in the helper files.\n",
    "from ImageRead import *\n",
    "from QNN import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_o = [1 for i in range(25)]+[0 for i in range(25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathY=r'../images/dataset/Original/galaxy/'\n",
    "pathN=r'../images/dataset/Original/No-galaxy/'\n",
    "nameN=''\n",
    "nameY=''\n",
    "# a1 = imageResize(callImage(5,pathY,nameY),16)\n",
    "# a2 = imageResize(callImage(29,pathY,nameY),16)\n",
    "# # plt.imshow(a1,cmap='gray')\n",
    "# plt.imshow(a2,cmap='gray')\n",
    "# plt.imshow(b1,cmap='gray')\n",
    "# plt.imshow(b2,cmap='gray')\n",
    "inputY=[imageResize(callImage(i+1,pathY,nameY),16) for i in range(25)]\n",
    "inputN=[imageResize(callImage(i+1,pathN,nameN),16) for i in range(25)]\n",
    "input_combine = inputY+inputN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "idx=np.array([int(i) for i in range(50)]).flatten()\n",
    "\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "dataInput = list(input_combine[i] for i in idx )\n",
    "dataTarget = list( imageBinarize(input_combine[i]) for i in idx )\n",
    "\n",
    "data_target_o=list( target_o[i] for i in idx )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples_show = 5\n",
    "fig, axes = plt.subplots(nrows=2, ncols=n_samples_show, figsize=(20, 6))\n",
    "\n",
    "for i in range(n_samples_show):\n",
    "\n",
    "    axes[0,i].imshow(dataInput[i], cmap='gray')\n",
    "    axes[0,i].set_xticks([])\n",
    "    axes[0,i].set_yticks([])\n",
    "    axes[1,i].imshow(dataInput[i+5], cmap='gray')\n",
    "    axes[1,i].set_xticks([])\n",
    "    axes[1,i].set_yticks([])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from qiskit.circuit.parameter import Parameter\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
    "from qiskit_machine_learning.circuit.library import QNNCircuit\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from torch.nn import Linear, CrossEntropyLoss, MSELoss\n",
    "from torch.optim import LBFGS, SGD, Adam\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier, VQC\n",
    "\n",
    "# Define the parity function\n",
    "def parity(x):\n",
    "    return f\"{bin(x)}\".count(\"1\") % 2\n",
    "\n",
    "# Model for LBFGS\n",
    "np.random.seed(3)\n",
    "\n",
    "nqubits = 6\n",
    "num_inputs = 256\n",
    "qc = QuantumCircuit(nqubits)\n",
    "\n",
    "# Encoding\n",
    "param_x = []\n",
    "for i in range(num_inputs):\n",
    "    param_x.append(Parameter('x' + str(i)))\n",
    "for i in range(8):\n",
    "    param_x.append(np.pi / 2)\n",
    "\n",
    "# Assuming you have a function `encoding` defined elsewhere\n",
    "feature_map = encoding(qc, param_x, 22)\n",
    "\n",
    "# Optimizing circuit PQC\n",
    "param_y = []\n",
    "for i in range(nqubits * 2):\n",
    "    param_y.append(Parameter('Î¸' + str(i)))\n",
    "\n",
    "# Assuming you have a function `circuit15` defined elsewhere\n",
    "ansatz = circuit15(qc, param_y)\n",
    "\n",
    "# Compose the feature map and ansatz into the quantum circuit\n",
    "qc.append(feature_map, range(nqubits))\n",
    "qc.append(ansatz, range(nqubits))\n",
    "\n",
    "# Use SamplerQNN instead of CircuitQNN\n",
    "qnn2 = SamplerQNN(\n",
    "    circuit=qc,\n",
    "    input_params=feature_map.parameters,\n",
    "    weight_params=ansatz.parameters,\n",
    "    interpret=parity,\n",
    "    output_shape=2\n",
    ")\n",
    "\n",
    "# Initialize weights for the QNN\n",
    "initial_weights = 0.1 * (2 * np.random.rand(qnn2.num_weights) - 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer and loss function\n",
    "\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "optimizer = LBFGS(model2.parameters(),lr=0.05)\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "X= [normlaizeData(dataInput[i].flatten()) for i in range(50)]\n",
    "y01= [data_target_o[i] for i in range(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.777549743652344\n",
      "35.66697692871094\n",
      "34.570335388183594\n",
      "33.22208786010742\n",
      "31.85173797607422\n",
      "30.984848022460938\n",
      "30.836833953857422\n",
      "30.748531341552734\n",
      "30.67437744140625\n",
      "30.61083984375\n",
      "30.556110382080078\n",
      "30.508686065673828\n",
      "30.467330932617188\n",
      "30.431076049804688\n",
      "30.399106979370117\n",
      "30.37078094482422\n",
      "30.34559440612793\n",
      "30.323108673095703\n",
      "30.302978515625\n",
      "30.28489875793457\n",
      "30.268648147583008\n",
      "30.25398826599121\n",
      "30.24076271057129\n",
      "30.22880744934082\n",
      "30.218000411987305\n",
      "30.208215713500977\n",
      "30.199356079101562\n",
      "30.19131851196289\n",
      "30.18404197692871\n",
      "30.177446365356445\n",
      "30.171466827392578\n",
      "30.166038513183594\n",
      "30.16112518310547\n",
      "30.156665802001953\n",
      "30.152629852294922\n",
      "30.148967742919922\n",
      "30.145654678344727\n",
      "30.142642974853516\n",
      "30.139923095703125\n",
      "30.137454986572266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(30.2686, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "# start training\n",
    "\n",
    "model2.train()    # set model to training mode\n",
    "\n",
    "# define objective function\n",
    "def closure():\n",
    "    optimizer.zero_grad()                                  # initialize gradient\n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())\n",
    "    loss.backward()                                        # backward pass\n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer\n",
    "optimizer.step(closure)\n",
    "optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer and loss function\n",
    "\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "optimizer = LBFGS(model2.parameters(),lr=0.05)\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "X= [normlaizeData(dataInput[i].flatten()) for i in range(50)]\n",
    "y01= [data_target_o[i] for i in range(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.64811325073242\n",
      "35.54372024536133\n",
      "34.583099365234375\n",
      "33.46548080444336\n",
      "34.92763137817383\n",
      "33.943382263183594\n",
      "33.3530387878418\n",
      "33.160621643066406\n",
      "32.918704986572266\n",
      "32.557430267333984\n",
      "32.2894172668457\n",
      "32.128395080566406\n",
      "32.01044845581055\n",
      "31.910511016845703\n",
      "31.814376831054688\n",
      "31.707338333129883\n",
      "31.57135009765625\n",
      "31.401521682739258\n",
      "31.247360229492188\n",
      "31.13759994506836\n",
      "31.060617446899414\n",
      "30.993940353393555\n",
      "30.934581756591797\n",
      "30.878589630126953\n",
      "30.827341079711914\n",
      "30.77460289001465\n",
      "30.718544006347656\n",
      "30.65656852722168\n",
      "30.589841842651367\n",
      "30.522985458374023\n",
      "30.46346092224121\n",
      "30.415023803710938\n",
      "30.37604522705078\n",
      "30.344024658203125\n",
      "30.316993713378906\n",
      "30.29376792907715\n",
      "30.273433685302734\n",
      "30.255414962768555\n",
      "30.239213943481445\n",
      "30.22450065612793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(31.0606, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "# start training\n",
    "\n",
    "model2.train()    # set model to training mode\n",
    "\n",
    "# define objective function\n",
    "def closure():\n",
    "    optimizer.zero_grad()                                  # initialize gradient\n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())\n",
    "    loss.backward()                                        # backward pass\n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer\n",
    "optimizer.step(closure)\n",
    "optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "# traning model accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# define optimizer and loss function\n",
    "from torch import Tensor\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "optimizer = LBFGS(model2.parameters(),lr=0.0006)\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "X= [normlaizeData(dataInput[i].flatten()) for i in range(50)]\n",
    "y01= [data_target_o[i] for i in range(50)]\n",
    "\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.777549743652344\n",
      "35.76658248901367\n",
      "35.66649627685547\n",
      "35.56280517578125\n",
      "35.4554328918457\n",
      "35.34437561035156\n",
      "35.22959518432617\n",
      "35.111106872558594\n",
      "34.98897933959961\n",
      "34.86327362060547\n",
      "34.73408508300781\n",
      "34.6015510559082\n",
      "34.465850830078125\n",
      "34.3271598815918\n",
      "34.18574523925781\n",
      "34.04186248779297\n",
      "33.89581298828125\n",
      "33.747947692871094\n",
      "33.59864807128906\n",
      "33.448341369628906\n",
      "33.297462463378906\n",
      "33.14649963378906\n",
      "31.910097122192383\n",
      "31.8469295501709\n",
      "31.813581466674805\n",
      "31.778547286987305\n",
      "31.74177360534668\n",
      "31.703874588012695\n",
      "31.665477752685547\n",
      "31.6272029876709\n",
      "31.589582443237305\n",
      "31.55307388305664\n",
      "31.517988204956055\n",
      "31.484527587890625\n",
      "31.452789306640625\n",
      "31.422805786132812\n",
      "31.394527435302734\n",
      "31.367900848388672\n",
      "31.34282112121582\n",
      "31.31919288635254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(33.2975, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "# start training\n",
    "\n",
    "model2.train()    # set model to training mode\n",
    "\n",
    "# define objective function\n",
    "def closure():\n",
    "    optimizer.zero_grad()                                  # initialize gradient\n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())\n",
    "    loss.backward()                                        # backward pass\n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer\n",
    "optimizer.step(closure)\n",
    "optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# traning model accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate 0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# define optimizer and loss function\n",
    "from torch import Tensor\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "optimizer = LBFGS(model2.parameters(),lr=0.07)\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "X= [normlaizeData(dataInput[i].flatten()) for i in range(50)]\n",
    "y01= [data_target_o[i] for i in range(50)]\n",
    "\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.64811325073242\n",
      "35.50145721435547\n",
      "34.130165100097656\n",
      "32.58714294433594\n",
      "30.83588981628418\n",
      "30.67334747314453\n",
      "30.545894622802734\n",
      "30.412790298461914\n",
      "30.290376663208008\n",
      "30.187480926513672\n",
      "30.103849411010742\n",
      "30.03590965270996\n",
      "29.980018615722656\n",
      "29.933347702026367\n",
      "29.893814086914062\n",
      "29.859893798828125\n",
      "29.83043670654297\n",
      "29.80458641052246\n",
      "29.781648635864258\n",
      "29.761093139648438\n",
      "29.742490768432617\n",
      "29.72548484802246\n",
      "29.709779739379883\n",
      "29.695125579833984\n",
      "29.68130874633789\n",
      "29.668176651000977\n",
      "29.655567169189453\n",
      "29.64336395263672\n",
      "29.63149642944336\n",
      "29.619918823242188\n",
      "29.608671188354492\n",
      "29.597822189331055\n",
      "29.587520599365234\n",
      "29.577953338623047\n",
      "29.56929588317871\n",
      "29.561634063720703\n",
      "29.554969787597656\n",
      "29.54922103881836\n",
      "29.544267654418945\n",
      "29.53997039794922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(29.7425, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "# start training\n",
    "\n",
    "model2.train()    # set model to training mode\n",
    "\n",
    "# define objective function\n",
    "def closure():\n",
    "    optimizer.zero_grad()                                  # initialize gradient\n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())\n",
    "    loss.backward()                                        # backward pass\n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer\n",
    "optimizer.step(closure)\n",
    "optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "# traning model accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TestModel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy25data: 0.8\n",
      "Accuracy50data: 0.74\n"
     ]
    }
   ],
   "source": [
    "target_o = [1 for i in range(25)]+[0 for i in range(25)]\n",
    "\n",
    "pathY=r'../dataset/Original/galaxy1/'\n",
    "pathN=r'../dataset/Original/no-galaxy1/'\n",
    "nameN=''\n",
    "nameY=''\n",
    "inputY=[imageResize(callImage(i+1,pathY,nameY),16) for i in range(25)]\n",
    "inputN=[imageResize(callImage(i+1,pathN,nameN),16) for i in range(25)]\n",
    "input_combine = inputY+inputN\n",
    "\n",
    "np.random.seed(0)\n",
    "idx=np.array([int(i) for i in range(50)]).flatten()\n",
    "\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "dataInput = list(input_combine[i] for i in idx )\n",
    "dataTarget = list( imageBinarize(input_combine[i]) for i in idx )\n",
    "\n",
    "data_target_o=list( target_o[i] for i in idx )\n",
    "\n",
    "Xtest= [normlaizeData(dataInput[i].flatten()) for i in range(25)]\n",
    "y01test= [data_target_o[i] for i in range(25)]\n",
    "\n",
    "Xtest1= [normlaizeData(dataInput[i].flatten()) for i in range(50)]\n",
    "y01test1= [data_target_o[i] for i in range(50)]\n",
    "\n",
    "y_predict = []\n",
    "for x in Xtest:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy25data:', sum(y_predict == np.array(y01test))/len(np.array(y01test)))\n",
    "\n",
    "y_predict1 = []\n",
    "for x in Xtest1:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict1 += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy50data:', sum(y_predict1 == np.array(y01test1))/len(np.array(y01test1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
